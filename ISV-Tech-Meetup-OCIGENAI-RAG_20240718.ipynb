{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e322051-e7df-4351-aed3-611861fd5ba7",
   "metadata": {},
   "source": [
    "## Oracle 23ai Vector Store와 OCI Gen AI LLM (Cohere Command R+)을 활용한 RAG 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5854d-fef8-493e-8a5e-c92b6d4dab1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "source": [
    "### 1. Oracle Database 23ai 접속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1672590f-1923-4a5d-a01b-718a56bc4ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connected to the Oracle Database 23.4.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import oracledb\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"oci.env\")\n",
    "\n",
    "username = config[\"DATABASE\"][\"USERNAME\"]\n",
    "password = config[\"DATABASE\"][\"PASSWORD\"]\n",
    "host = config[\"DATABASE\"][\"HOST\"]\n",
    "port = config[\"DATABASE\"][\"PORT\"]\n",
    "service_name = config[\"DATABASE\"][\"SERVICE_NAME\"]\n",
    "table_name = config[\"DATABASE\"][\"TABLE_NAME_CV_LANG\"]\n",
    "compartment_id = config[\"OCI\"][\"compartment_id\"]\n",
    "dsn=host+\":\"+port+\"/\"+service_name\n",
    "upstage_api_key=config[\"APIKEY\"][\"UPSTAGE_API_KEY\"]\n",
    "\n",
    "try:\n",
    "    oracledb.init_oracle_client()\n",
    "    connection = oracledb.connect(user=username, password=password, dsn=dsn)\n",
    "    print(\"\\nConnected to the Oracle Database 23.4.\\n\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"\\nConnection failed!\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf3fb74-7c9f-407d-94f6-9461c11c9b2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Load the document\n",
    "#### 텍스트 추출: Oracle Doc Loader, Oracle Text Splitter 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b2c1b25-021c-4b0d-9115-9e10b916737e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs loaded: 1\n",
      "Doc 1: chunks# 89\n",
      "Doc 1: page_content: ··························································6 2. 기업/산업 ▹ 스태빌리티AI, 차세대 이미지 생성 AI '스테이블 디퓨전 3' 프리뷰 버전 공개 ·················7 ▹ 오픈AI, metadata: {'SOURCE MIME TYPE': 'application/pdf', 'creation date': '4/8/2024 12:46:55 AM', 'author': 'spri', 'revision date': '4/8/2024 12:46:55 AM', 'Creator': '\\rHwp 2018 10.0.0.13764', 'publisher': 'Hancom PDF 1.3.0.542', 'PDFVersion': '\\r1.4', '_oid': '6692cd256aa918ee066f7ec2c41c25e4', '_file': '/home/opc/23ai_rag_demo/app/pdfs/SPRi_AI_Brief_4.pdf', 'id': '5', 'document_id': '1'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.oracleai import OracleTextSplitter \n",
    "from langchain_community.document_loaders.oracleai import OracleDocLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "pdf_file=\"/home/opc/23ai_rag_demo/app/pdfs/SPRi_AI_Brief_4.pdf\"\n",
    "\n",
    "splitter_params = {\"BY\" :\"words\", \"MAX\": 200, \"OVERLAP\": 10, \"SPLIT\": \"sentence\", \"LANGUAGE\": \"KOREAN\", \"NORMALIZE\": \"all\"}\n",
    "splitter = OracleTextSplitter(conn=connection, params=splitter_params)\n",
    "\n",
    "chunks_with_mdata = []\n",
    "doc_origin = Document\n",
    "max_lengh_oracle_allow=9000\n",
    "counter = 0  \n",
    "document_num = 0\n",
    "\n",
    "loader_params = {}        \n",
    "loader_params['file'] = pdf_file\n",
    "# instantiate loader, splitter and embedder\n",
    "loader = OracleDocLoader(conn=connection, params=loader_params)\n",
    "\n",
    "# read the docs, convert blob docs to clob docs\n",
    "docs = loader.load()\n",
    "print(f\"Number of docs loaded: {len(docs)}\")\n",
    "\n",
    "for id, doc in enumerate(docs, start=1):\n",
    "    #remove line break from the text document\n",
    "    doc.page_content = doc.page_content.replace(\"\\n\", \"\")\n",
    "    doc_origin.page_content = doc.page_content\n",
    "    # check the doc\n",
    "    if len(doc.page_content)>max_lengh_oracle_allow :\n",
    "        #reduce the text to max_lengh_oracle_allow\n",
    "        doc.page_content = doc.page_content[:9000]\n",
    "    document_num += 1\n",
    "    \n",
    "    # chunk the doc\n",
    "    chunks = splitter.split_text(doc_origin.page_content)\n",
    "    print(f\"Doc {id}: chunks# {len(chunks)}\")\n",
    "\n",
    "#For each chunk create chunk_metadata with \n",
    "for ic, chunk in enumerate(chunks, start=1):\n",
    "    counter += 1  \n",
    "    chunk_metadata = doc.metadata.copy()  \n",
    "    chunk_metadata['id'] = str(counter)  \n",
    "    chunk_metadata['document_id'] = str(document_num)\n",
    "    # chunk_metadata['document_summary'] = str(summ[0])\n",
    "    chunks_with_mdata.append(Document(page_content=str(chunk), metadata=chunk_metadata))\n",
    "\n",
    "print(f\"Doc {id}: page_content: { chunks_with_mdata[4].page_content} metadata: {chunks_with_mdata[4].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f66c2-5d51-4c3f-8d33-fa1c49383d10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Embedding 및 벡터 데이터베이스에 입력\n",
    "#### Embedding Model: OCI GenAI cohere.embed-multilingual-v3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "257bfda1-1266-4cd8-913c-d4ec4f3c6587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents loading, chunking and generating embeddings are complete.\n",
      "Vectorizing and inserting chunks duration: 2.6 sec.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.embeddings.oracleai import OracleEmbeddings\n",
    "from langchain_community.vectorstores import oraclevs\n",
    "from langchain_community.vectorstores.oraclevs import OracleVS\n",
    "\n",
    "embedder = OCIGenAIEmbeddings(\n",
    "            model_id=\"cohere.embed-multilingual-v3.0\",\n",
    "            service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "            compartment_id= compartment_id)\n",
    "distance_strategy=DistanceStrategy.COSINE    #COSINE\n",
    "table_name_with_strategy = table_name+'_'+distance_strategy\n",
    "\n",
    "s1time = time.time()\n",
    "vector_store = OracleVS.from_documents(chunks_with_mdata, embedder, client=connection, table_name=table_name_with_strategy, distance_strategy=distance_strategy)\n",
    "\n",
    "### Create Oracle HNSW Index\n",
    "oraclevs.create_index(client=connection,vector_store=vector_store, params={\n",
    "    \"idx_name\": \"hnsw\"+table_name_with_strategy, \"idx_type\": \"HNSW\"\n",
    "})\n",
    "s2time = time.time()\n",
    "\n",
    "if vector_store is not None:\n",
    "    print( f\"Documents loading, chunking and generating embeddings are complete.\\nVectorizing and inserting chunks duration: {round(s2time - s1time, 1)} sec.\")\n",
    "else:\n",
    "    print(\"\\nFailed to get the VectorStore populated.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ba42f-52f3-4630-88bd-cf6321290f42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. Retriever 생성 및 및 유사도 검색\n",
    "#### Embedding Model: OCI GenAI cohere.embed-multilingual-v3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0aee0a5a-29b1-4eae-9415-8722cdba0bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_chunks=[Document(metadata={'SOURCE MIME TYPE': 'application/pdf', 'creation date': '4/8/2024 12:46:55 AM', 'author': 'spri', 'revision date': '4/8/2024 12:46:55 AM', 'Creator': '\\rHwp 2018 10.0.0.13764', 'publisher': 'Hancom PDF 1.3.0.542', 'PDFVersion': '\\r1.4', '_oid': '6692cd256aa918ee066f7ec2c41c25e4', '_file': '/home/opc/23ai_rag_demo/app/pdfs/SPRi_AI_Brief_4.pdf', 'id': '1', 'document_id': '1'}, page_content='2024년 4월호2024년 4월호Ⅰ.인공지능 산업 동향 브리프 1. 정책/법제 ▹ 유럽의회 본회의에서 세계 최초의 AI 법 통과 ·····································································1 ▹ 유럽평의회,'), Document(metadata={'SOURCE MIME TYPE': 'application/pdf', 'creation date': '4/8/2024 12:46:55 AM', 'author': 'spri', 'revision date': '4/8/2024 12:46:55 AM', 'Creator': '\\rHwp 2018 10.0.0.13764', 'publisher': 'Hancom PDF 1.3.0.542', 'PDFVersion': '\\r1.4', '_oid': '6692cd256aa918ee066f7ec2c41c25e4', '_file': '/home/opc/23ai_rag_demo/app/pdfs/SPRi_AI_Brief_4.pdf', 'id': '19', 'document_id': '1'}, page_content='··············17Ⅰ. 인공지능 산업 동향 브리프1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육1유럽의회 본회의에서 세계 최초의 AI 법 통과 n 유럽의회에서 AI 법이 본회의 표결을 통과하여 EU 회원국 승인을 거쳐 올해 안에 발효 예정으로, 발효 후 단계적으로 도입되어 2년 후 전면 시행됨 n EU 집행위 산하에 신설된 유럽 AI 사무국이 EU 회원국 전반에 걸쳐 AI 법의 일관된 적용을 위한 핵심적인 역할을 수행할 전망 KEY Contents £ 유럽의회, 찬성'), Document(metadata={'SOURCE MIME TYPE': 'application/pdf', 'creation date': '4/8/2024 12:46:55 AM', 'author': 'spri', 'revision date': '4/8/2024 12:46:55 AM', 'Creator': '\\rHwp 2018 10.0.0.13764', 'publisher': 'Hancom PDF 1.3.0.542', 'PDFVersion': '\\r1.4', '_oid': '6692cd256aa918ee066f7ec2c41c25e4', '_file': '/home/opc/23ai_rag_demo/app/pdfs/SPRi_AI_Brief_4.pdf', 'id': '20', 'document_id': '1'}, page_content='523표와 반대 46표의 압도적 찬성으로 AI 법(AI Act) 가결 n 유럽의회 본회의에서 2024년 3월 13일 AI 법을 찬성 523표, 반대 46표, 기권 49표의 압도적 찬성으로 가결했으며, EU 회원국 승인을 얻어 올해 안에 발효될 예정 ∙ AI 법은 고위험 AI로부터 기본권, 민주주의, 법치, 환경 지속 가능성을 보호하는 동시에 혁신을 촉진하여 유럽을 글로벌 AI 리더로 자리매김하는 것을 목표로 함 ∙ AI 법은 EU 회원국의 승인을 거쳐 관보 게재 20일 후에 발효되며, 발효 후 단계적으로 도입되어 2년 뒤 전면적으로 시행 예정 n AI')]\n",
      "Search for the user question in the Oracle Database 23ai and return similar chunks duration: 0.2 sec.\n"
     ]
    }
   ],
   "source": [
    "vector_store = OracleVS(client=connection, \n",
    "                        embedding_function=embedder, \n",
    "                        table_name=table_name_with_strategy, \n",
    "                        distance_strategy=distance_strategy)\n",
    "\n",
    "user_question = (\"최초의 AI법은 언제 통과 되었니? 출처나 참고 문서도 같이 알려줘.\");\n",
    "\n",
    "if user_question:\n",
    "    s1time =  time.time()\n",
    "    result_chunks = vector_store.similarity_search(user_question, 3)\n",
    "    s2time = time.time()\n",
    "    print(f\"result_chunks={result_chunks}\\nSearch for the user question in the Oracle Database 23ai and return similar chunks duration: {round(s2time - s1time, 1)} sec.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e53dc-5aee-47f8-9b59-0cf65e23b878",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5. Langchain RAG\n",
    "#### Vector Store Retriver cohere.command-r-plus LLM 모델 및  사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76822773-5b47-4290-ac8f-11974e13b319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response=최초의 AI 법은 2024년 3월 13일 유럽의회 본회의에서 통과되었습니다. 이 법은 EU 회원국의 승인을 거쳐 올해 안에 발효될 예정이며, 발효 후 2년 뒤全面적으로 시행될 예정입니다. \n",
      "\n",
      "출처: SPRi AI Brief, 2024년 4월호\n",
      "Send user question and ranked chunks to LLM and get answer duration: 3.5 sec.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "chat = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-r-plus\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=compartment_id,\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500, \"top_p\": 0.6}\n",
    ")\n",
    "\n",
    "message = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        질문-답변 업무를 돕는 AI 어시스턴트입니다. \n",
    "        문서의 내용을 참고해서 답변해 주세요.:\n",
    "        \\n\\n\n",
    "        {context}\",\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{human}\"),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(message)\n",
    "\n",
    "chain = {\n",
    "\"context\": vector_store.as_retriever(search_kwargs={'k':3}),\n",
    "\"human\": RunnablePassthrough(),\n",
    "} | prompt | chat | StrOutputParser()\n",
    "\n",
    "s1time=time.time()\n",
    "response = chain.invoke(user_question)\n",
    "s2time=time.time()\n",
    "\n",
    "print( f\"response={response}\\nSend user question and ranked chunks to LLM and get answer duration: {round(s2time - s1time, 1)} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343fb447-8636-4811-8252-1c2426e4de2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 6. Langchain RAG\n",
    "#### SQL Retriver, cohere.command-r-plus LLM 모델 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3af32805-76c0-40f5-9079-3f056b2bd057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response=세계 최초의 AI 법은 2024년 3월 13일 유럽의회 본회의에서 통과되었습니다. 이 법은 EU 회원국의 승인을 얻어 올해 안에 발효될 예정이며, 고위험 AI로부터 기본권, 민주주의, 법치, 환경 지속 가능성을 보호하고 혁신을 촉진하여 유럽을 글로벌 AI 리더로 자리매김하는 것을 목표로 합니다. 참고 문서로는 '2024년 4월호 - 인공지능 산업 동향 브리프'가 있습니다.\n",
      "Send user question and ranked chunks to LLM and get answer duration: 3.0 sec.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "embedder_params = {\"provider\": \"ocigenai\", \n",
    "                   \"credential_name\": \"YH_OCI_CRED\", \n",
    "                   \"url\": \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText\", \n",
    "                   \"model\": \"cohere.embed-multilingual-v3.0\"}\n",
    "\n",
    "sql_query = f\"\"\"SELECT text, metadata \n",
    "FROM {table_name_with_strategy}\n",
    "ORDER BY vector_distance(\n",
    "    embedding, \n",
    "    (\n",
    "        SELECT TO_VECTOR(et.embed_vector) AS embed_vector \n",
    "        FROM DBMS_VECTOR_CHAIN.UTL_TO_EMBEDDINGS(\n",
    "            :query, \n",
    "            JSON(:embedder_params)\n",
    "        ) t, \n",
    "        JSON_TABLE (\n",
    "            t.column_value, \n",
    "            '$[*]' COLUMNS (\n",
    "                embed_id NUMBER PATH '$.embed_id', \n",
    "                embed_data VARCHAR2(4000) PATH '$.embed_data', \n",
    "                embed_vector CLOB PATH '$.embed_vector'\n",
    "            )\n",
    "        ) et\n",
    "    )\n",
    ", COSINE)\n",
    "FETCH FIRST 3 ROWS ONLY\n",
    "\"\"\"\n",
    "\n",
    "cur = connection.cursor()\n",
    "cur.execute(sql_query, {'query': user_question, 'embedder_params': json.dumps(embedder_params)})\n",
    "rows = cur.fetchall()\n",
    "\n",
    "documents = [Document(page_content=row[0]) if isinstance(row[0], str) else Document(page_content=row[0].read(), metadata=json.loads(row[1].read())) for row in rows]\n",
    "\n",
    "context = '\\n\\n'.join([d.page_content for d in documents])\n",
    "\n",
    "chat = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-r-plus\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=\"ocid1.compartment.oc1..aaaaaaaal7ipgtkkohxxjdbgxmqap4jx3gloyd52f33ujv3thz45uwopjmna\",\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500, \"top_p\": 0.6},\n",
    ")\n",
    "\n",
    "message = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        질문-답변 업무를 돕는 AI 어시스턴트입니다. \n",
    "        문서의 내용을 참고해서 답변해 주세요.:\n",
    "        \\n\\n\n",
    "        {context}\",\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{human}\"),\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(message)\n",
    "\n",
    "chain = {\n",
    "    \"context\": RunnablePassthrough(),\n",
    "    \"human\": RunnablePassthrough()\n",
    "} | prompt | chat | StrOutputParser()\n",
    "\n",
    "s1time = time.time()\n",
    "response = chain.invoke({\n",
    "    \"human\": user_question,\n",
    "    \"context\": context  # pass context as a string here\n",
    "})\n",
    "s2time = time.time()\n",
    "\n",
    "print( f\"response={response}\\nSend user question and ranked chunks to LLM and get answer duration: {round(s2time - s1time, 1)} sec.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
